{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Relevant Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "import seaborn as sb\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\r\n",
    "from sklearn.feature_selection import SelectKBest,chi2\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\r\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Fulldf = pd.read_csv('Data/Train_Dataset.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#list of columns which are in object type, to convert to numeric type\r\n",
    "initdf=Fulldf.drop(columns=['ID','Score_Source_1','Score_Source_2','Score_Source_3','Credit_Bureau'])\r\n",
    "\r\n",
    "#list of columns which are in object type, to convert to numeric type\r\n",
    "toconvert_type_list=['Client_Income','Credit_Amount','Loan_Annuity','Population_Region_Relative','Age_Days','Employed_Days','Registration_Days','ID_Days']\r\n",
    "\r\n",
    "#list of columns which are categorical type\r\n",
    "categorical_list = ['Accompany_Client','Client_Income_Type','Client_Education','Client_Marital_Status','Client_Gender','Loan_Contract_Type','Client_Housing_Type','Client_Occupation','Client_Permanent_Match_Tag','Client_Contact_Work_Tag','Type_Organization']\r\n",
    "\r\n",
    "#list of columns which are numerical type\r\n",
    "numeric_list=['Bike_Owned','Active_Loan','House_Own','Child_Count','Own_House_Age','Mobile_Tag','Homephone_Tag','Workphone_Working','Client_Family_Members','Cleint_City_Rating','Application_Process_Day','Application_Process_Hour','Social_Circle_Default','Phone_Change','Default']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### visualize the target variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = sb.countplot(initdf['Default'])\r\n",
    "g.set_xticklabels(['Not Default','Default'])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data visualization for categorical columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "figure,axes = plt.subplots(6,2,figsize=(30,30))\r\n",
    "for index,cat_col in enumerate(categorical_list):\r\n",
    "    row,col = index//2,index%2\r\n",
    "    sb.countplot(x=cat_col,data=Fulldf,hue='Default',ax=axes[row,col])\r\n",
    "\r\n",
    "\r\n",
    "plt.subplots_adjust(hspace=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### convert object type columns to float type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for x in initdf:\r\n",
    "    if x in toconvert_type_list:\r\n",
    "        initdf[x] = pd.to_numeric(initdf[x],errors = 'coerce')\r\n",
    "        numeric_list.append(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get a list of categorical type columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categ_dummy_list=[]\r\n",
    "for x in initdf:\r\n",
    "    if x in categorical_list:      \r\n",
    "        categ_dummy_list.append(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### check columns with XNA values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "totcount =0\r\n",
    "count=0\r\n",
    "t=0\r\n",
    "for x in initdf:\r\n",
    "    for xx in initdf[x]:\r\n",
    "        if xx == 'XNA':\r\n",
    "            if t==0:\r\n",
    "                t =t+1\r\n",
    "            count =count +1   \r\n",
    "            totcount =totcount +1\r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop 'Type_Organization' from initdf and categ_dummy_lis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "initdf=initdf.drop(['Type_Organization'],axis=1)\r\n",
    "categ_dummy_list.remove('Type_Organization')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove rows with XNA values in gender column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for x in initdf['Client_Gender']:\r\n",
    "    if x == 'XNA':\r\n",
    "        initdf.drop(initdf[initdf['Client_Gender'] == 'XNA'].index, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check unique values of each categorical variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count = 0\r\n",
    "for x in initdf:\r\n",
    "    if x in categ_dummy_list:\r\n",
    "        count =len(Fulldf[x].value_counts())\r\n",
    "    count = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reducing number of categories"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "initdf['Accompany_Client'] = [x if x in ('Alone','Relative') else 'Other' for x in initdf['Accompany_Client']]\r\n",
    "initdf['Client_Income_Type'] = [x if x in ('Service','Commercial','Retired' , 'Unemployed' , 'Student') else 'Other' for x in initdf['Client_Income_Type']]\r\n",
    "initdf['Client_Education'] = [x if x in ('Secondary','Graduation') else 'Other' for x in initdf['Client_Education']]\r\n",
    "initdf['Client_Housing_Type'] = [x if x =='Home' else 'Other' for x in initdf['Client_Housing_Type']]\r\n",
    "initdf['Client_Marital_Status'] = [x if x =='M' else 'Other' for x in initdf['Client_Marital_Status']]\r\n",
    "initdf['Client_Occupation'] = [x if x in ('Laborers','Sales','Core','Managers','Drivers','High skill tech','Medicine') else 'Other' for x in initdf['Client_Occupation']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count = 0\r\n",
    "for x in initdf:\r\n",
    "    if x in categ_dummy_list:\r\n",
    "        count =len(Fulldf[x].value_counts())\r\n",
    "    count = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking Unique values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "initdf['Loan_Annuity'].unique()\r\n",
    "initdf['Phone_Change'].unique()\r\n",
    "initdf['Client_Education'].unique()\r\n",
    "initdf['Client_Occupation'].unique()\r\n",
    "initdf['Client_Gender'].unique()\r\n",
    "initdf['Client_Income_Type'].unique()\r\n",
    "initdf['Child_Count'].unique()\r\n",
    "initdf['Workphone_Working'].unique()\r\n",
    "initdf['Application_Process_Hour'].unique()\r\n",
    "initdf['Cleint_City_Rating'].unique()\r\n",
    "initdf['Homephone_Tag'].unique()\r\n",
    "initdf['Car_Owned'].unique()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### fucntion to encode categorical variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def encode_df(df, todummy_list):\r\n",
    "    for x in todummy_list:\r\n",
    "        df[x] = LabelEncoder().fit_transform(df[x])\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a list of categorical values in necessary columns before encoding to use when labeling inputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "education = initdf['Client_Education'].unique()\r\n",
    "occupation = initdf['Client_Occupation'].unique()\r\n",
    "income_type = initdf['Client_Income_Type'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "initdf = encode_df(initdf, categ_dummy_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a list of categorical values in necessary columns After encoding to use when labeling inputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "education_label = initdf['Client_Education'].unique()\r\n",
    "occupation_label = initdf['Client_Occupation'].unique()\r\n",
    "income_type_label = initdf['Client_Income_Type'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(income_type_label)\r\n",
    "print(income_type)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handle missing values\r\n",
    "### missing data count"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "initdf.isnull().sum().sort_values(ascending=False).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove columns which has null values more than 30%"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tot =0\r\n",
    "for x in initdf:\r\n",
    "    tot = initdf[x].isnull().sum()\r\n",
    "    if (tot/len(initdf.index)) > 0.3 :\r\n",
    "        print(\"Droped column'\",x,\"' and total number of null values:\",initdf[x].isnull().sum())\r\n",
    "        del initdf[x]\r\n",
    "    tot=0   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Imputer in sklearn.preprocessing, impute missing values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imp = SimpleImputer(strategy='mean')\r\n",
    "imp.fit(initdf)\r\n",
    "initdf = pd.DataFrame(data=imp.transform(initdf),columns=initdf.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert days to years"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "days = ['Age_Days','Employed_Days','Registration_Days','ID_Days','Phone_Change']\r\n",
    "for var in days:\r\n",
    "    initdf[var] = [math.ceil(x/365) if x != '' else null for x in initdf[var]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate all the variabl's max and min values\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for column in initdf:\r\n",
    "    maxVal = initdf[column].max()\r\n",
    "    minVal = initdf[column].min()\r\n",
    "    \r\n",
    "    print('{} Max:{} -- Min:{}'.format(column, maxVal,minVal))\r\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove unwanted rows \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Population_Region_Relative values must be between 1-0\r\n",
    "val=0\r\n",
    "for col in initdf['Population_Region_Relative']:\r\n",
    "    if col>1:\r\n",
    "        initdf.drop(initdf[initdf['Population_Region_Relative'] > 1].index, inplace = True)\r\n",
    "        val+=1 \r\n",
    "val    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val=0\r\n",
    "for col in initdf['Employed_Days']:\r\n",
    "    if col>100:\r\n",
    "        #print(col)\r\n",
    "        val+=1 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "initdf=initdf.drop(columns=['Employed_Days'])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlations between variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Correlations between variables\r\n",
    "plt.figure(figsize=(30,30))\r\n",
    "sb.heatmap(initdf.corr(), annot=True, square=True, cmap='coolwarm')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Function to get variables which has greater than value of Correlations for given threshold value "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def correlation(dataset, threshold):\r\n",
    "    col_correlation = set()  # Set of all the names of correlated columns\r\n",
    "    corr_matrix = dataset.corr()\r\n",
    "    for i in range(len(corr_matrix.columns)):\r\n",
    "        for j in range(i):\r\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\r\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\r\n",
    "                col_correlation.add(colname)\r\n",
    "    return col_correlation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "correlation_features = correlation(initdf, 0.5)\r\n",
    "correlation_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting the best Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = initdf.iloc[:,:-1]  #independent columns\r\n",
    "y = initdf.iloc[:,-1]    #target column \r\n",
    "#apply SelectKBest class to extract top best features\r\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\r\n",
    "fit = bestfeatures.fit(X,y)\r\n",
    "dfscores = pd.DataFrame(fit.scores_)\r\n",
    "dfcolumns = pd.DataFrame(X.columns)\r\n",
    "#concat two dataframes for better visualization \r\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\r\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\r\n",
    "topfeatures=featureScores.nlargest(20,'Score')\r\n",
    "# print(featureScores.nlargest(20,'Score'))  #print 10 best features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get final data set with top 17 best features with class variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Finaldf=initdf[['Credit_Amount','Client_Income','Loan_Annuity','Age_Days','Phone_Change','Registration_Days','Client_Education','Client_Occupation','Client_Gender','Client_Income_Type','Child_Count','Workphone_Working','Application_Process_Hour','Cleint_City_Rating','Homephone_Tag','Car_Owned','Default']]\r\n",
    "Finaldf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "X = Finaldf.drop('Default', axis=1).values# Input features (attributes)\r\n",
    "y = Finaldf['Default'].values # Target vector\r\n",
    "print('X shape: {}'.format(np.shape(X)))\r\n",
    "print('y shape: {}'.format(np.shape(y)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Undersampling to balance the class distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler \r\n",
    "\r\n",
    "under = RandomUnderSampler()\r\n",
    "X, y = under.fit_resample(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()\r\n",
    "x_train =scaler.fit_transform(x_train)\r\n",
    "x_test =scaler.transform(x_test) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the dataset into training set & testing set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiate and fit model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "model = LogisticRegression(max_iter=200)\r\n",
    "model.fit(x_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test = model.predict(x_test)\r\n",
    "classes = ['Not Default','Default']\r\n",
    "def plot_confusionmatrix(pred,test,dom):\r\n",
    "    print(f'{dom} Confusion matrix')\r\n",
    "    cf = confusion_matrix(pred,test)\r\n",
    "    sb.heatmap(cf,annot=True,yticklabels=classes\r\n",
    "               ,xticklabels=classes,cmap='Blues', fmt='g')\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.show()    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training Accuracy\r\n",
    "print(\"Training Accuracy is: \", model.score(x_train, y_train))\r\n",
    "#Test Accuracy\r\n",
    "print(\"Testing Accuracy is: \", model.score(x_test, y_test))\r\n",
    "\r\n",
    "\r\n",
    "plot_confusionmatrix(y_test,prediction_test,dom='Test')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(classification_report(y_test,prediction_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cross_val_score(model,X,y,cv=20)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('penv': venv)"
  },
  "interpreter": {
   "hash": "ee25deaa157146aa5ab983906bb6a065bee9b1c63fc59cc7edac0e5187fae9dd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}